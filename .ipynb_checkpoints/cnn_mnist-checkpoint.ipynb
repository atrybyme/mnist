{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atri/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import important libraries\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building cnn model for mnist\n",
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30,(5,5),input_shape=(28,28,1),activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the data from csv file.\n",
    "#the file contains 42000 labelled examples\n",
    "_data_raw = (np.genfromtxt('train.csv',delimiter=','))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we import sklearn just to shuffle the dataset\n",
    "import sklearn\n",
    "x_tr,y = sklearn.utils.shuffle((_data_raw[:,1:])/255,_data_raw[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding\n",
    "y = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape and split the data for training and testing\n",
    "x= np.reshape(x_tr,(42000,28,28,1))\n",
    "x_train = x[0:41000]\n",
    "y_train = y[0:41000]\n",
    "x_test = x[41000:42000]\n",
    "y_test = y[41000:42000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40590 samples, validate on 410 samples\n",
      "Epoch 1/10\n",
      "40590/40590 [==============================] - 4s 107us/step - loss: 0.4239 - acc: 0.8680 - val_loss: 0.0934 - val_acc: 0.9683\n",
      "Epoch 2/10\n",
      "40590/40590 [==============================] - 3s 85us/step - loss: 0.1187 - acc: 0.9642 - val_loss: 0.0613 - val_acc: 0.9780\n",
      "Epoch 3/10\n",
      "40590/40590 [==============================] - 3s 79us/step - loss: 0.0863 - acc: 0.9727 - val_loss: 0.0580 - val_acc: 0.9829\n",
      "Epoch 4/10\n",
      "40590/40590 [==============================] - 3s 80us/step - loss: 0.0723 - acc: 0.9777 - val_loss: 0.0497 - val_acc: 0.9829\n",
      "Epoch 5/10\n",
      "40590/40590 [==============================] - 3s 80us/step - loss: 0.0617 - acc: 0.9808 - val_loss: 0.0493 - val_acc: 0.9805\n",
      "Epoch 6/10\n",
      "40590/40590 [==============================] - 3s 83us/step - loss: 0.0558 - acc: 0.9816 - val_loss: 0.0352 - val_acc: 0.9878\n",
      "Epoch 7/10\n",
      "40590/40590 [==============================] - 3s 83us/step - loss: 0.0511 - acc: 0.9839 - val_loss: 0.0426 - val_acc: 0.9878\n",
      "Epoch 8/10\n",
      "40590/40590 [==============================] - 3s 82us/step - loss: 0.0438 - acc: 0.9862 - val_loss: 0.0492 - val_acc: 0.9829\n",
      "Epoch 9/10\n",
      "40590/40590 [==============================] - 3s 82us/step - loss: 0.0416 - acc: 0.9871 - val_loss: 0.0399 - val_acc: 0.9829\n",
      "Epoch 10/10\n",
      "40590/40590 [==============================] - 3s 81us/step - loss: 0.0401 - acc: 0.9873 - val_loss: 0.0365 - val_acc: 0.9927\n",
      "41000/41000 [==============================] - 2s 37us/step\n",
      "ACCURACY ON Training sET 0.9952439024390244\n"
     ]
    }
   ],
   "source": [
    "#call the cnn model already build\n",
    "model = cnn_model()\n",
    "\n",
    "#fit the data over training dataset, by deviding the into 128 batches and using 1 batch at a time\n",
    "#the model will fit by iterating 10 times over the whole training data\n",
    "#at each iteration 1% of the whole training data will be used for validation and rest for training\n",
    "model.fit(x_train,y_train,batch_size=128,epochs=10,verbose=1,validation_split=0.01)\n",
    "l = model.predict(x_train,verbose=1,batch_size=100)\n",
    "train_prediction = np.argmax(l,axis=1)\n",
    "\n",
    "#predictiong over Training Set\n",
    "e= (np.equal(np.argmax(y_train,axis=1),train_prediction))*1\n",
    "print(\"ACCURACY ON Training sET\",(np.sum(e))/len(y_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 62us/step\n",
      "ACCURACY ON Testing sET 99.4\n"
     ]
    }
   ],
   "source": [
    "#Prediction over the testing and checking test accuracy\n",
    "\n",
    "l = model.predict(x_test,verbose=1)\n",
    "prediction_test= np.argmax(l,axis=1)\n",
    "e= (np.equal(np.argmax(y_test,axis=1),prediction_test))*1\n",
    "print(\"ACCURACY ON Testing sET\",((np.sum(e))/len(y_test))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
