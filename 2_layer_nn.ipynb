{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atri/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "##import important libraries\n",
    "from random import *\n",
    "import numpy as np\n",
    "import matplotlib as mt\n",
    "import preprocessing as pr\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "##we imported sklearn just to shuffle the data\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##build your tiny 1 hiddenlayer neural network model\n",
    "def nn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(800, input_dim=784, kernel_initializer='normal',bias_initializer='normal',activation='relu'))\n",
    "    model.add(Dense(10, kernel_initializer='normal', activation='softmax'))\n",
    "    ##model will use adam optimize\n",
    "    ##the lost function used is categorial cross-entropy\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import data from csv file the data contains 42000 labelled examples\n",
    "training_data_raw = (np.genfromtxt('train.csv',delimiter=','))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##shuffle the data\n",
    "x,y = sklearn.utils.shuffle((training_data_raw[:,1:])/255,training_data_raw[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##doing one hot encoding\n",
    "y = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data for training and testing\n",
    "x_train = x[0:41000]\n",
    "y_train = y[0:41000]\n",
    "x_test = x[41000:42000]\n",
    "y_test = y[41000:42000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40590 samples, validate on 410 samples\n",
      "Epoch 1/10\n",
      "40590/40590 [==============================] - 1s 25us/step - loss: 0.3344 - acc: 0.9040 - val_loss: 0.1441 - val_acc: 0.9634\n",
      "Epoch 2/10\n",
      "40590/40590 [==============================] - 1s 23us/step - loss: 0.1349 - acc: 0.9620 - val_loss: 0.1000 - val_acc: 0.9634\n",
      "Epoch 3/10\n",
      "40590/40590 [==============================] - 1s 23us/step - loss: 0.0892 - acc: 0.9745 - val_loss: 0.0820 - val_acc: 0.9683\n",
      "Epoch 4/10\n",
      "40590/40590 [==============================] - 1s 23us/step - loss: 0.0616 - acc: 0.9829 - val_loss: 0.0624 - val_acc: 0.9829\n",
      "Epoch 5/10\n",
      "40590/40590 [==============================] - 1s 23us/step - loss: 0.0448 - acc: 0.9885 - val_loss: 0.0418 - val_acc: 0.9854\n",
      "Epoch 6/10\n",
      "40590/40590 [==============================] - 1s 23us/step - loss: 0.0323 - acc: 0.9919 - val_loss: 0.0447 - val_acc: 0.9805\n",
      "Epoch 7/10\n",
      "40590/40590 [==============================] - 1s 23us/step - loss: 0.0244 - acc: 0.9947 - val_loss: 0.0313 - val_acc: 0.9927\n",
      "Epoch 8/10\n",
      "40590/40590 [==============================] - 1s 23us/step - loss: 0.0173 - acc: 0.9965 - val_loss: 0.0302 - val_acc: 0.9878\n",
      "Epoch 9/10\n",
      "40590/40590 [==============================] - 1s 23us/step - loss: 0.0143 - acc: 0.9972 - val_loss: 0.0316 - val_acc: 0.9927\n",
      "Epoch 10/10\n",
      "40590/40590 [==============================] - 1s 27us/step - loss: 0.0101 - acc: 0.9985 - val_loss: 0.0309 - val_acc: 0.9878\n",
      "41000/41000 [==============================] - 0s 11us/step\n",
      "ACCURACY ON Training sET 99.93658536585366\n",
      "1000/1000 [==============================] - 0s 26us/step\n",
      "ACCURACY ON Testing sET 98.0\n"
     ]
    }
   ],
   "source": [
    "#calling the model\n",
    "model = nn_model()\n",
    "#fitting the model over training dataset by splitting the dataset into 200 batches ,\n",
    "#running 1 batch at a time and iterating 200 times over the whole dataset.\n",
    "#99% of training data will be used for training and 1% of the training data will be used for validationat each iteration\n",
    "model.fit(x_train,y_train,batch_size=200,epochs=10,verbose=1,validation_split=0.01)\n",
    "\n",
    "#predict the output for training data\n",
    "l = model.predict(x_train,verbose=1,batch_size=100)\n",
    "train_prediction = np.argmax(l,axis=1)\n",
    "e= (np.equal(np.argmax(y_train,axis=1),train_prediction))*1\n",
    "print(\"ACCURACY ON Training sET\",((np.sum(e))/len(y_train))*100)\n",
    "\n",
    "\n",
    "#predict the output for tesating data\n",
    "l = model.predict(x_test,verbose=1)\n",
    "prediction_test= np.argmax(l,axis=1)\n",
    "\n",
    "#check the accuracy over training data\n",
    "e= (np.equal(np.argmax(y_test,axis=1),prediction_test))*1\n",
    "print(\"ACCURACY ON Testing sET\",((np.sum(e))/len(y_test))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
